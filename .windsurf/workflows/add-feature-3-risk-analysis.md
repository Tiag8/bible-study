---
description: Workflow Add-Feature (3/9) - Risk Analysis (AnÃ¡lise de Riscos)
auto_execution_mode: 1
---

## ğŸ“š PrÃ©-requisito

Ler ANTES: `docs/PLAN.md`, `docs/TASK.md`, `README.md`, `AGENTS.md`

---

# Workflow 3/11: Risk Analysis (AnÃ¡lise de Riscos e MitigaÃ§Ãµes)

**Terceiro workflow** de 11 etapas modulares para adicionar nova funcionalidade.

**O que acontece**:
- Fase 5: AnÃ¡lise de Riscos Detalhada
- Fase 6: EstratÃ©gias de MitigaÃ§Ã£o
- **GATE 2**: UsuÃ¡rio aprova plano de riscos

**Por que etapa dedicada**:
- âœ… AnÃ¡lise profunda APÃ“S escolher soluÃ§Ã£o
- âœ… Riscos especÃ­ficos da soluÃ§Ã£o escolhida
- âœ… UsuÃ¡rio pode ajustar mitigaÃ§Ãµes

---

## ğŸ¤– USO MÃXIMO DE AGENTES

**SEMPRE paralelo**: 3-5 agentes (anÃ¡lise tÃ©cnica + seguranÃ§a + negÃ³cio + mitigaÃ§Ãµes)
**BenefÃ­cio**: 20-30min vs 2-3h

---

## ğŸ›¡ï¸ Fase 5: AnÃ¡lise de Riscos Detalhada

### ğŸš¨ REGRA: RISCOS BASEADOS EM EVIDÃŠNCIAS

**NUNCA criar riscos baseados em**:
- âŒ "Pode acontecer" (teoria sem dados)
- âŒ "Geralmente Ã© problemÃ¡tico" (genÃ©rico)
- âŒ Medo/paranoia sem fundamento

**SEMPRE basear riscos em**:
- âœ… **Dados do projeto** (logs, mÃ©tricas, histÃ³rico)
- âœ… **Casos passados** (debugging-cases/, ADRs)
- âœ… **Pesquisa validada** (issues conhecidos, CVEs, benchmarks)
- âœ… **Fatos mensurÃ¡veis** (carga atual, volume dados)

### 5.1 Riscos TÃ©cnicos

**Performance**
- **Risco**: [ESPECÃFICO + MENSURÃVEL]
- **EvidÃªncia**: [mÃ©trica atual / caso passado / benchmark]
- **Probabilidade/Impacto**: Alta-MÃ©dia-Baixa / Alto-MÃ©dio-Baixo
- **Severidade**: ğŸ”´ / ğŸŸ¡ / ğŸŸ¢

**Breaking Changes**
- **Risco**: [ESPECÃFICO + MENSURÃVEL]
- **EvidÃªncia**: [teste quebrado / dependency check / caso similar]
- **Probabilidade/Impacto**: Alta-MÃ©dia-Baixa / Alto-MÃ©dio-Baixo
- **Severidade**: ğŸ”´ / ğŸŸ¡ / ğŸŸ¢

### 5.2 Riscos de SeguranÃ§a

**ExposiÃ§Ã£o de Dados & InjeÃ§Ã£o**
- **Risco**: [ESPECÃFICO + MENSURÃVEL]
- **EvidÃªncia**: [security scan / CVE / caso passado]
- **Probabilidade/Impacto**: Alta-MÃ©dia-Baixa / Alto-MÃ©dio-Baixo
- **Severidade**: ğŸ”´ / ğŸŸ¡ / ğŸŸ¢

### 5.3 Riscos de NegÃ³cio

**Impacto UsuÃ¡rio**
- **Risco**: [ESPECÃFICO + MENSURÃVEL]
- **EvidÃªncia**: [feedback real / analytics / teste usuÃ¡rio]
- **Probabilidade/Impacto**: Alta-MÃ©dia-Baixa / Alto-MÃ©dio-Baixo
- **Severidade**: ğŸ”´ / ğŸŸ¡ / ğŸŸ¢

### 5.4 Plano de Rollback

**OpÃ§Ãµes** (ordem preferÃªncia):
1. **Git revert**: Bugs cÃ³digo, banco OK â†’ `git revert <hash>`
2. **Restaurar backup**: Migration quebrou â†’ `./scripts/restore-supabase.sh`
3. **Feature flag**: Desabilitar sem redeploy
4. **Redeploy anterior**: Bugs crÃ­ticos produÃ§Ã£o

**Tempo estimado**: [X minutos]

---

## ğŸ”§ Fase 6: EstratÃ©gias de MitigaÃ§Ã£o

### 6.1 MitigaÃ§Ãµes TÃ©cnicas

**Performance & Escalabilidade**
- âœ… Ãndices WHERE/JOIN, `.select()` especÃ­fico, LIMIT queries
- âœ… Cache (useMemo, React Query), paginaÃ§Ã£o, lazy loading
- âœ… Monitorar tempo queries (< 500ms)

**Breaking Changes & Complexidade**
- âœ… Testes regressÃ£o, migration backward-compatible
- âœ… Testar features relacionadas
- âœ… DocumentaÃ§Ã£o inline, testes unitÃ¡rios, cÃ³digo modular
- âœ… ADR se decisÃ£o arquitetural

### 6.2 MitigaÃ§Ãµes SeguranÃ§a

**Dados SensÃ­veis & InjeÃ§Ã£o**
- âœ… RLS habilitado, queries com filtros ownership
- âœ… Supabase query builder (`.eq()`, `.filter()`), NUNCA raw SQL
- âœ… Inputs validados, sem `dangerouslySetInnerHTML`
- âœ… Logs sanitizados

**AutenticaÃ§Ã£o/AutorizaÃ§Ã£o**
- âœ… Auth tokens headers (nÃ£o URL/params)
- âœ… RLS valida ownership TODAS tabelas
- âœ… CORS domÃ­nios especÃ­ficos (nÃ£o *)
- âœ… Tokens expiram

### 6.3 Backup e ContingÃªncia

**OpÃ§Ã£o A: Dump LÃ³gico** (mudanÃ§as pequenas)
- `./scripts/backup-supabase.sh`
- PrÃ³s: RÃ¡pido, rollback < 5min
- Cons: NÃ£o testa migration isolado

**OpÃ§Ã£o B: Preview Branch** (mudanÃ§as complexas)
- `supabase branches create feature-backup`
- PrÃ³s: Ambiente isolado, testa migration
- Cons: Mais lento, requer Supabase Pro

**Escolher**: [Dump LÃ³gico / Preview Branch]
**Justificativa**: [Por que]

### 6.4 Checklist Testes

- [ ] TypeScript, ESLint, testes, build passam
- [ ] Feature funciona, UI correta, performance < 500ms
- [ ] NÃ£o quebrou features existentes
- [ ] Security scan passa, ZERO secrets, RLS, inputs sanitizados

---

## âœ… ValidaÃ§Ã£o: Riscos Reais e FactÃ­veis (OBRIGATÃ“RIO)

**ANTES do GATE 2**, validar que TODOS riscos identificados sejam:

### Checklist Riscos
- [ ] **Risco ESPECÃFICO** (nÃ£o genÃ©rico "pode degradar")?
  - âŒ "Performance pode cair"
  - âœ… "Query lifetracker_habits pode exceder 500ms (atual: 320ms, +50 habits = 800ms estimado)"

- [ ] **Risco MENSURÃVEL** (dados concretos)?
  - MÃ©trica atual: [valor]
  - Threshold problema: [valor]
  - EvidÃªncia: [log/teste/mÃ©trica]

- [ ] **EvidÃªncia DOCUMENTADA** para cada risco?
  - [ ] Dados projeto: [mÃ©trica/log especÃ­fico]
  - [ ] Caso passado: [debugging-cases/XXX ou ADR/XXX]
  - [ ] Pesquisa validada: [link issue/CVE/benchmark]
  - âŒ SE zero evidÃªncias: REMOVER risco (paranoia)

- [ ] **Probabilidade FUNDAMENTADA** (nÃ£o "achismo")?
  - Alta: JÃ¡ aconteceu OU altamente provÃ¡vel (evidÃªncia)
  - MÃ©dia: Casos similares conhecidos (ref)
  - Baixa: PossÃ­vel mas sem precedente (edge case)

**SE algum risco nÃ£o passa**: â›” **REMOVER** (nÃ£o Ã© risco real, Ã© medo infundado)

**Exemplo Real**:
- âŒ RISCO TEÃ“RICO: "App pode ficar lento com muitos usuÃ¡rios"
- âœ… RISCO FACTÃVEL: "Dashboard atual 1.2s com 10 users (medido), estimado 5s com 100 users (cÃ¡lculo queries * avg), threshold 2s (UX guideline)"

---

## ğŸš¨ REGRA CRÃTICA: MITIGAÃ‡Ã•ES BASEADAS EM EVIDÃŠNCIAS

**NUNCA propor mitigaÃ§Ãµes baseadas em**:
- âŒ IntuiÃ§Ã£o ("acho que deveria...")
- âŒ SuposiÃ§Ãµes fictÃ­cias ("pode ser que...")
- âŒ Teoria sem validaÃ§Ã£o ("geralmente Ã© bom ter...")
- âŒ "Best practices" genÃ©ricas sem contexto
- âŒ Feeling ou achismo

**SEMPRE basear mitigaÃ§Ãµes em**:
- âœ… **Dados reais do projeto** (logs, mÃ©tricas, testes)
- âœ… **DocumentaÃ§Ã£o oficial** (Supabase docs, React docs, RFCs)
- âœ… **Casos passados documentados** (docs/debugging-cases/, ADRs)
- âœ… **Pesquisa web validada** (Stack Overflow, GitHub issues, benchmarks)
- âœ… **Fatos mensurÃ¡veis** (performance real, uso real de memÃ³ria)

### Checklist ValidaÃ§Ã£o de EvidÃªncias (OBRIGATÃ“RIO)

Para CADA mitigaÃ§Ã£o proposta, documentar:

**1. Fonte da MitigaÃ§Ã£o**
- [ ] **De onde veio esta mitigaÃ§Ã£o?**
  - ğŸ“š DocumentaÃ§Ã£o oficial: [link/seÃ§Ã£o]
  - ğŸ” Pesquisa web: [URL + snippet relevante]
  - ğŸ“ Caso passado: [docs/debugging-cases/XXX.md]
  - ğŸ“Š Dados projeto: [mÃ©trica/log/teste especÃ­fico]

**2. EvidÃªncia de EficÃ¡cia**
- [ ] **Como sabemos que funciona?**
  - Benchmark: [dados concretos]
  - Caso de sucesso: [link/referÃªncia]
  - Teste local: [resultado medido]
  - ValidaÃ§Ã£o empÃ­rica: [evidÃªncia]

**3. Contexto AplicÃ¡vel**
- [ ] **Por que aplica ao NOSSO caso?**
  - CenÃ¡rio similar: [comparaÃ§Ã£o]
  - Stack compatÃ­vel: [versÃµes/tech]
  - Escala equivalente: [users/dados/carga]
  - Problema idÃªntico: [sintoma matching]

### Exemplo

**âŒ ERRADO**: "Redis Ã© best practice" (achismo)
**âœ… CORRETO**: "React Query cache (docs: tanstack.com/query, teste: 2.3sâ†’0.1s, caso: debugging-cases/001)"

### Red Flags - Rejeitar SE:
- âŒ Fonte = "achismo" / "geralmente"
- âŒ Zero evidÃªncia eficÃ¡cia
- âŒ Contexto diferente (escala/stack)
- âŒ Pesquisa < 3 fontes confiÃ¡veis

### Ferramentas
- **Web**: `firecrawl_search()` (MCP)
- **Docs**: `context7_get_library_docs()` (MCP)
- **Casos**: `grep -r "keyword" docs/debugging-cases/`

### ValidaÃ§Ã£o Final

- [ ] **TODAS** mitigaÃ§Ãµes tÃªm fonte documentada?
- [ ] **TODAS** mitigaÃ§Ãµes tÃªm evidÃªncia de eficÃ¡cia?
- [ ] **TODAS** mitigaÃ§Ãµes tÃªm contexto validado?
- [ ] **ZERO** mitigaÃ§Ãµes baseadas em intuiÃ§Ã£o/achismo?

**SE alguma mitigaÃ§Ã£o falhar**: â›” **REMOVER ou SUBSTITUIR** por mitigaÃ§Ã£o com evidÃªncias.

**Ver**: `.claude/CLAUDE.md` â†’ REGRA #5 "Advogado do Diabo" (questÃµes 4-6 sobre fontes)

---

## âœ‹ GATE 2: AprovaÃ§Ã£o do Plano de Riscos

**âš ï¸ PARADA OBRIGATÃ“RIA - RevisÃ£o UsuÃ¡rio**

**Revise e confirme:**

1. **Riscos identificados fazem sentido?**
   - Falta risco importante? Algum superestimado?

2. **MitigaÃ§Ãµes adequadas?**
   - MitigaÃ§Ãµes suficientes? Precisa adicional?

3. **EstratÃ©gia backup apropriada?**
   - Dump lÃ³gico suficiente ou Preview Branch?
   - Tempo rollback aceitÃ¡vel?

4. **Plano rollback claro?**
   - Sabe o que fazer se der errado?
   - Tempo recuperaÃ§Ã£o aceitÃ¡vel?

**OpÃ§Ãµes**:
- **Aprovar** - Digite: `Aprovar` ou `OK` ou `Prosseguir`
- **Ajustar** - Digite: `Ajustar` + explicaÃ§Ã£o
- **Adicionar risco** - Digite: `Risco: [descriÃ§Ã£o]`
- **Modificar mitigaÃ§Ã£o** - Digite: `MitigaÃ§Ã£o: [mudanÃ§a]`

**Aguardando aprovaÃ§Ã£o...** ğŸš¦

---

## ğŸš¨ ValidaÃ§Ã£o Anti-Over-Engineering (OBRIGATÃ“RIO)

**CRÃTICO**: Validar se mitigaÃ§Ãµes propostas nÃ£o sÃ£o over-engineered.

### Checklist YAGNI/KISS para MitigaÃ§Ãµes
- [ ] **MitigaÃ§Ã£o resolve risco REAL** (nÃ£o teÃ³rico)?
  - EvidÃªncia do risco: [dado concreto/caso passado]
  - vs "pode acontecer teoricamente" âŒ

- [ ] **MitigaÃ§Ã£o mais SIMPLES**?
  - OpÃ§Ã£o simplificada: [descrever]
  - Por que inadequada: [evidÃªncia]

- [ ] **Complexidade de mitigaÃ§Ã£o justificada**?
  - Severidade do risco: Alta/MÃ©dia/Baixa
  - Probabilidade: Alta/MÃ©dia/Baixa
  - ROI da mitigaÃ§Ã£o: [custo vs benefÃ­cio]

- [ ] **Posso validar mitigaÃ§Ã£o com teste simples**?
  - Teste: [como validar eficÃ¡cia]
  - CritÃ©rio de sucesso: [mÃ©trica]

### Red Flags em MitigaÃ§Ãµes
- [ ] âŒ Infra complexa para problema simples (ex: Redis para 10 users)
- [ ] âŒ Over-monitoring (ex: APM completo para protÃ³tipo)
- [ ] âŒ MitigaÃ§Ã£o > 3x mais complexa que risco
- [ ] âŒ "Best practice" sem evidÃªncia de necessidade

**Se 2+ red flags**: â›” SIMPLIFICAR mitigaÃ§Ãµes

**Exemplo Real**:
- âŒ Risco: "App pode ficar lento" â†’ Implementar CDN global + caching distribuÃ­do
- âœ… Risco: "App pode ficar lento" â†’ React Query cache + lazy loading (validar DEPOIS se precisar mais)

**Ver**: `.claude/CLAUDE.md` â†’ REGRA #10 Anti-Over-Engineering

---

## ğŸ” RCA (SE APLICÃVEL)

**Quando**: Risco recorrente, bug durante anÃ¡lise.

**Template 5 Whys**:
1. Por quÃª? â†’ [R1]
2. Por quÃª R1? â†’ [R2]
3. Por quÃª R2? â†’ [R3]
4. Por quÃª R3? â†’ [R4]
5. Por quÃª R4? â†’ [R5 = Causa Raiz SISTÃŠMICA]

**AÃ§Ã£o**: [Prevenir recorrÃªncia]

**Ver**: `.claude/CLAUDE.md` â†’ REGRA #4

---

## ğŸ‘¿ Advogado do Diabo: ValidaÃ§Ã£o Riscos (OBRIGATÃ“RIO)

**ANTES de prosseguir**, responder:

### ValidaÃ§Ã£o SuposiÃ§Ãµes
- [ ] **E se oposto for verdade?** E se risco NÃƒO Ã© tÃ£o alto?
- [ ] **O que NÃƒO vemos?** Riscos esquecidos?

### ValidaÃ§Ã£o Fontes â­ (CRÃTICO)
- [ ] **Pesquisamos casos similares?**
  - âœ… docs/debugging-cases/
  - âœ… ADRs anteriores
  - âŒ Faltou: [gaps]

- [ ] **TODAS mitigaÃ§Ãµes TÃŠM fontes documentadas?**
  - [ ] Fonte 1: [link/path/referÃªncia concreta]
  - [ ] Fonte 2: [link/path/referÃªncia concreta]
  - [ ] Fonte 3: [link/path/referÃªncia concreta]
  - âŒ SE < 3 fontes: mitigaÃ§Ã£o REJEITADA (achismo)

- [ ] **EvidÃªncia de eficÃ¡cia COMPROVADA?**
  - [ ] Benchmark/teste: [dados mensurÃ¡veis]
  - [ ] Caso de sucesso: [referÃªncia documentada]
  - âŒ SE apenas "best practice" teÃ³rica: REJEITAR

- [ ] **Contexto validado?**
  - [ ] Stack/versÃµes compatÃ­veis?
  - [ ] Escala similar ao nosso projeto?
  - [ ] Problema idÃªntico (nÃ£o apenas parecido)?

### ValidaÃ§Ã£o Abordagem
- [ ] **RCA para riscos recorrentes?**
  - Risco jÃ¡ aconteceu? Se SIM: por que nÃ£o prevenido?
  - 5 Whys aplicados?

- [ ] **Como validar mitigaÃ§Ãµes antes produÃ§Ã£o?**
  - Staging disponÃ­vel? Testes carga? Rollback testado?

**Ver**: `.claude/CLAUDE.md` â†’ "Advogado do Diabo"

**Resultado**: âœ… APROVADO | âš ï¸ AJUSTAR | âŒ REJEITAR

---

## âœ… Checkpoint: Riscos Analisados e Mitigados!

**Plano riscos aprovado!**

**PrÃ³xima etapa:** Preparar ambiente (backup, branch, sync) e implementaÃ§Ã£o!

---

## ğŸ§  Meta-Learning

**Objetivo**: Melhorias sistÃªmicas (nÃ£o pontuais).

**QuestÃµes**:
1. EficiÃªncia workflow (nota 1-10): __/10
2. IteraÃ§Ãµes usuÃ¡rio: __ (se > 3, identificar causa)
3. Gaps: validaÃ§Ã£o faltou? gate falhou? comando repetitivo?
4. RCA aplicado se problema? (5 Whys â†’ causa sistÃªmica)

**AÃ§Ãµes**: Documentar em Workflow 8a (consolidaÃ§Ã£o final)

---

## ğŸš¨ REGRA CRÃTICA: ANTI-ROI

**NUNCA calcule ou mencione**:
- âŒ ROI (Return on Investment)
- âŒ Tempo de execuÃ§Ã£o/produÃ§Ã£o
- âŒ "Horas economizadas"
- âŒ Estimativas temporais (Xmin vs Ymin)

**Por quÃª**:
- Projeto desenvolvido por IA (nÃ£o humanos)
- IA executa tarefas em paralelo (nÃ£o linear)
- CÃ¡lculos consomem tokens sem valor
- Polui documentaÃ§Ã£o com dados irrelevantes

**Permitido**:
- âœ… EvidÃªncias concretas (cÃ³digo, logs, testes)
- âœ… ComparaÃ§Ãµes qualitativas ("mais rÃ¡pido", "mais eficiente")
- âœ… MÃ©tricas tÃ©cnicas (latÃªncia, throughput, memory usage)

**Regra**: NEVER guess time/ROI. Use dados concretos ou nÃ£o mencione.

---

## ğŸ”„ PrÃ³ximo Workflow

```
Acionar: .windsurf/workflows/add-feature-4-setup.md
```

**Ou**: `/add-feature-4-setup`

---

**Criado**: 2025-10-27 | **Atualizado**: 2025-11-08 | **Parte**: 3/11 | **PrÃ³ximo**: Setup

---

## ğŸ”— ReferÃªncias

- `docs/WORKFLOW_BRANCHES.md`: CriaÃ§Ã£o segura branches
- `./scripts/create-feature-branch.sh`: ProteÃ§Ã£o perda cÃ³digo

---
