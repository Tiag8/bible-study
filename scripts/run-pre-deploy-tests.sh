#!/bin/bash

################################################################################
# Script: run-pre-deploy-tests.sh
# DescriÃ§Ã£o: Executa checklist completo de testes prÃ©-deploy (SoluÃ§Ã£o B+C)
# Autor: Claude (via Tiago)
# Data: 2025-11-05
# VersÃ£o: 1.0.0
#
# Uso:
#   ./scripts/run-pre-deploy-tests.sh [--category CATEGORIA] [--parallel]
#
# OpÃ§Ãµes:
#   --category: Executar apenas uma categoria (1-6)
#   --parallel: Usar agentes paralelos (recomendado)
#   --quick: Executar apenas testes crÃ­ticos
#   --report: Gerar relatÃ³rio final
#
# Exemplos:
#   ./scripts/run-pre-deploy-tests.sh --parallel
#   ./scripts/run-pre-deploy-tests.sh --category 1
#   ./scripts/run-pre-deploy-tests.sh --quick --report
################################################################################

set -e  # Exit on error

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Counters
TOTAL_TESTS=0
PASSED_TESTS=0
FAILED_TESTS=0
CRITICAL_FAILURES=0

# Log file
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_FILE="test-results-${TIMESTAMP}.log"
REPORT_FILE="docs/qa/test-report-${TIMESTAMP}.md"

################################################################################
# Helper Functions
################################################################################

log_info() {
  echo -e "${BLUE}â„¹ï¸  $1${NC}" | tee -a "$LOG_FILE"
}

log_success() {
  echo -e "${GREEN}âœ… $1${NC}" | tee -a "$LOG_FILE"
  ((PASSED_TESTS++))
  ((TOTAL_TESTS++))
}

log_failure() {
  echo -e "${RED}âŒ $1${NC}" | tee -a "$LOG_FILE"
  ((FAILED_TESTS++))
  ((TOTAL_TESTS++))
}

log_warning() {
  echo -e "${YELLOW}âš ï¸  $1${NC}" | tee -a "$LOG_FILE"
}

log_critical_failure() {
  echo -e "${RED}ğŸ”¥ CRITICAL FAILURE: $1${NC}" | tee -a "$LOG_FILE"
  ((CRITICAL_FAILURES++))
  ((FAILED_TESTS++))
  ((TOTAL_TESTS++))
}

section_header() {
  echo ""
  echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
  echo -e "${BLUE}$1${NC}"
  echo -e "${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
  echo ""
}

################################################################################
# Test Functions
################################################################################

# CATEGORIA 1: TESTES DE CÃ“DIGO (15 min)
run_code_tests() {
  section_header "CATEGORIA 1: TESTES DE CÃ“DIGO"

  # 1.1 TypeScript Compilation
  log_info "1.1 - TypeScript Compilation..."
  if npm run build > /dev/null 2>&1; then
    log_success "TypeScript compilation passed"
  else
    log_critical_failure "TypeScript compilation failed"
  fi

  # 1.2 ESLint
  log_info "1.2 - ESLint (Code Quality)..."
  LINT_OUTPUT=$(npm run lint 2>&1 || true)
  LINT_ERRORS=$(echo "$LINT_OUTPUT" | grep -c "error" || true)
  LINT_WARNINGS=$(echo "$LINT_OUTPUT" | grep -c "warning" || true)

  if [ "$LINT_ERRORS" -eq 0 ]; then
    log_success "ESLint passed (Warnings: $LINT_WARNINGS)"
  else
    log_critical_failure "ESLint failed ($LINT_ERRORS errors)"
  fi

  # 1.3 Unit Tests
  log_info "1.3 - Unit Tests..."
  if [ -f "package.json" ] && grep -q "test:unit" package.json; then
    if npm run test:unit > /dev/null 2>&1; then
      log_success "Unit tests passed"
    else
      log_critical_failure "Unit tests failed"
    fi
  else
    log_warning "Unit tests script not found (skipping)"
  fi

  # 1.4 Integration Tests
  log_info "1.4 - Integration Tests..."
  if [ -f "package.json" ] && grep -q "test:integration" package.json; then
    if npm run test:integration > /dev/null 2>&1; then
      log_success "Integration tests passed"
    else
      log_critical_failure "Integration tests failed"
    fi
  else
    log_warning "Integration tests script not found (skipping)"
  fi

  # 1.5 E2E Tests
  log_info "1.5 - E2E Tests (Smoke)..."
  if [ -f "package.json" ] && grep -q "test:e2e" package.json; then
    if npm run test:e2e > /dev/null 2>&1; then
      log_success "E2E tests passed"
    else
      log_warning "E2E tests failed (non-critical)"
    fi
  else
    log_warning "E2E tests script not found (skipping)"
  fi

  # 1.6 Coverage Report
  log_info "1.6 - Coverage Report..."
  if [ -f "package.json" ] && grep -q "test:coverage" package.json; then
    COVERAGE_OUTPUT=$(npm run test:coverage 2>&1 || true)
    COVERAGE_PERCENT=$(echo "$COVERAGE_OUTPUT" | grep -oP 'All files.*?\|\s*\K[0-9.]+' | head -1 || echo "0")

    if (( $(echo "$COVERAGE_PERCENT >= 75" | bc -l 2>/dev/null || echo 0) )); then
      log_success "Coverage: ${COVERAGE_PERCENT}% (>75%)"
    elif (( $(echo "$COVERAGE_PERCENT >= 60" | bc -l 2>/dev/null || echo 0) )); then
      log_warning "Coverage: ${COVERAGE_PERCENT}% (acceptable, but <75%)"
    else
      log_critical_failure "Coverage: ${COVERAGE_PERCENT}% (<60%)"
    fi
  else
    log_warning "Coverage script not found (skipping)"
  fi
}

# CATEGORIA 2: TESTES DE FEATURE (90 min)
run_feature_tests() {
  section_header "CATEGORIA 2: TESTES DE FEATURE"

  log_warning "Feature tests require manual execution or external test scripts"
  log_info "Please refer to: docs/qa/PRE_DEPLOY_CHECKLIST_BC.md - Section 2"

  # Placeholder - Real implementation would call specific test scripts
  log_info "2.1 - FASE 4.8 (Area Selection): 8 scenarios"
  log_info "2.2 - FASE 4.9 (Habit Creation): 18 scenarios"
  log_info "2.3 - FASE 4.10 (First Log): 3 scenarios"
  log_info "2.4 - Recovery Flows: 21 scenarios"
  log_info "2.5 - RAPPORT: 3 profiles"
  log_info "2.6 - Memory (RAG): Context retention"

  # Check if feature test scripts exist
  if [ -f "scripts/test-whatsapp-flow-complete.sh" ]; then
    log_info "Running WhatsApp flow tests..."
    if bash scripts/test-whatsapp-flow-complete.sh > /dev/null 2>&1; then
      log_success "WhatsApp flow tests passed"
    else
      log_failure "WhatsApp flow tests failed"
    fi
  else
    log_warning "WhatsApp flow test script not found (manual testing required)"
  fi
}

# CATEGORIA 3: TESTES DE UI/UX (30 min)
run_ui_tests() {
  section_header "CATEGORIA 3: TESTES DE UI/UX"

  log_info "3.1 - Message Quality (Manual review required)"
  log_warning "Please verify: typos, grammar, tone, emojis, clarity"

  log_info "3.2 - Button Functionality"
  if [ -f "scripts/test-uazapi-buttons.sh" ]; then
    if bash scripts/test-uazapi-buttons.sh > /dev/null 2>&1; then
      log_success "UAZAPI buttons functional"
    else
      log_failure "UAZAPI buttons failed"
    fi
  else
    log_warning "Button test script not found (manual testing required)"
  fi

  log_info "3.3 - Emoji Rendering (Visual inspection required)"
  log_warning "Manually verify: ğŸ‰ ğŸ’ª ğŸ”¥ âœ… render correctly"

  log_info "3.4 - Latency P95 < 3s"
  log_warning "Run: ./scripts/measure-latency.sh --users 10"

  log_info "3.5 - Celebration Quality (User feedback required)"
  log_warning "Survey 3 testers for celebration feedback"
}

# CATEGORIA 4: TESTES DE PERFORMANCE (60 min)
run_performance_tests() {
  section_header "CATEGORIA 4: TESTES DE PERFORMANCE"

  log_info "4.1 - Latency P50 < 2s"
  log_info "4.2 - Latency P95 < 3s"
  log_info "4.3 - Latency P99 < 5s"
  log_warning "Performance tests require load testing tools"
  log_warning "Recommended: k6, artillery, or custom load test script"

  log_info "4.4 - Token Budget < 1500 tokens/msg"
  log_warning "Analyze: ./scripts/analyze-token-usage.sh --messages 100"

  log_info "4.5 - Cache Hit Rate > 70%"
  log_warning "Test: ./scripts/test-cache-hit-rate.sh --warmup 100 --test 50"

  log_warning "All performance tests require manual execution"
}

# CATEGORIA 5: TESTES DE SEGURANÃ‡A (45 min)
run_security_tests() {
  section_header "CATEGORIA 5: TESTES DE SEGURANÃ‡A"

  # 5.1 Security Scan
  log_info "5.1 - Security Scan..."
  if [ -f "scripts/run-security-tests.sh" ]; then
    if bash scripts/run-security-tests.sh > /dev/null 2>&1; then
      log_success "Security scan passed"
    else
      log_critical_failure "Security scan failed"
    fi
  else
    log_warning "Security test script not found"
  fi

  # 5.2 Secrets Scan
  log_info "5.2 - Secrets Scan..."
  SECRETS_FOUND=$(git diff main | grep -iE '(password|api_key|secret|token|sk-|pk_)' || true)
  if [ -z "$SECRETS_FOUND" ]; then
    log_success "No secrets found in code"
  else
    log_critical_failure "Secrets detected in code!"
    echo "$SECRETS_FOUND" | tee -a "$LOG_FILE"
  fi

  # 5.3 RLS Check
  log_info "5.3 - RLS Policies..."
  if [ -f "scripts/check-rls-policies.sh" ]; then
    if bash scripts/check-rls-policies.sh > /dev/null 2>&1; then
      log_success "RLS policies configured"
    else
      log_critical_failure "RLS policies missing"
    fi
  else
    log_warning "RLS check script not found (manual verification required)"
  fi

  # 5.4 Input Sanitization
  log_info "5.4 - Input Sanitization..."
  log_warning "Test with: SQL injection, XSS, command injection, path traversal"

  # 5.5 HMAC Validation
  log_info "5.5 - HMAC Validation (Webhook)..."
  log_warning "Verify webhook signature validation is implemented"

  # 5.6 npm audit
  log_info "5.6 - npm audit..."
  AUDIT_OUTPUT=$(npm audit --audit-level=high 2>&1 || true)
  VULNERABILITIES=$(echo "$AUDIT_OUTPUT" | grep -oP '\d+ vulnerabilities' | grep -oP '\d+' | head -1 || echo "0")

  if [ "$VULNERABILITIES" -eq 0 ]; then
    log_success "No high/critical vulnerabilities found"
  else
    log_critical_failure "$VULNERABILITIES high/critical vulnerabilities found"
  fi

  # 5.7 Content Moderation
  log_info "5.7 - Content Moderation..."
  log_warning "Test with: profanity, offensive language, spam"

  # 5.8 Rate Limiting
  log_info "5.8 - Rate Limiting..."
  log_warning "Test: 35 messages/hour from single user"
}

# CATEGORIA 6: TESTES DE REGRESSÃƒO (60 min)
run_regression_tests() {
  section_header "CATEGORIA 6: TESTES DE REGRESSÃƒO"

  log_info "6.1 - Dashboard Load < 2s"
  log_warning "Manual test: Open web app dashboard and measure load time"

  log_info "6.2 - Habit Logging (Web)"
  log_warning "Manual test: Log habit entry via web app"

  log_info "6.3 - Assessment Load"
  log_warning "Manual test: Start assessment in web app"

  log_info "6.4 - AI Coach (Web)"
  log_warning "Manual test: Send message to AI Coach via web"

  log_info "6.5 - Authentication"
  log_warning "Manual test: Login/logout flow"

  log_info "6.6 - Habit Creation (Web)"
  log_warning "Manual test: Create habit via web form"

  log_info "6.7 - Notifications"
  log_warning "Manual test: If implemented, verify notifications work"

  log_info "6.8 - Mobile Responsiveness"
  log_warning "Manual test: Open web app on mobile (360px width)"

  log_warning "All regression tests require manual execution in browser"
}

################################################################################
# Report Generation
################################################################################

generate_report() {
  section_header "GENERATING TEST REPORT"

  cat > "$REPORT_FILE" <<EOF
# Test Report - Pre-Deploy Checklist B+C

**Generated**: $(date '+%Y-%m-%d %H:%M:%S')
**Environment**: Staging
**Branch**: $(git branch --show-current)
**Commit**: $(git rev-parse --short HEAD)

---

## Summary

| Metric | Value |
|--------|-------|
| Total Tests | $TOTAL_TESTS |
| Passed | $PASSED_TESTS |
| Failed | $FAILED_TESTS |
| Critical Failures | $CRITICAL_FAILURES |
| Success Rate | $(echo "scale=1; $PASSED_TESTS * 100 / $TOTAL_TESTS" | bc)% |

---

## Status

EOF

  if [ "$CRITICAL_FAILURES" -eq 0 ] && [ "$FAILED_TESTS" -le 6 ]; then
    echo "**âœ… DEPLOY APPROVED**" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
    echo "All critical tests passed. Deploy is safe to proceed." >> "$REPORT_FILE"
  else
    echo "**âŒ DEPLOY BLOCKED**" >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
    echo "Critical failures detected. Deploy is blocked until issues are resolved." >> "$REPORT_FILE"
    echo "" >> "$REPORT_FILE"
    echo "- Critical Failures: $CRITICAL_FAILURES" >> "$REPORT_FILE"
    echo "- Total Failures: $FAILED_TESTS (max allowed: 6)" >> "$REPORT_FILE"
  fi

  cat >> "$REPORT_FILE" <<EOF

---

## Detailed Log

See full log: \`$LOG_FILE\`

---

## Next Steps

EOF

  if [ "$CRITICAL_FAILURES" -eq 0 ] && [ "$FAILED_TESTS" -le 6 ]; then
    cat >> "$REPORT_FILE" <<EOF
1. âœ… Update \`docs/TASK.md\` marking tests as completed
2. âœ… Create release tag: \`git tag -a v1.0.0-mvp -m "MVP SoluÃ§Ã£o B+C"\`
3. âœ… Deploy to staging: \`./scripts/deploy-vps.sh staging\`
4. âœ… Run smoke tests in staging (10 min)
5. âœ… Deploy to production: \`./scripts/deploy-vps.sh production\`
6. âœ… Monitor production (10 min initial)

EOF
  else
    cat >> "$REPORT_FILE" <<EOF
1. âŒ DO NOT DEPLOY
2. ğŸ”§ Fix critical issues listed above
3. ğŸ”„ Re-run tests: \`./scripts/run-pre-deploy-tests.sh\`
4. âœ… Deploy only after approval

EOF
  fi

  echo "---" >> "$REPORT_FILE"
  echo "" >> "$REPORT_FILE"
  echo "**Report generated by**: run-pre-deploy-tests.sh v1.0.0" >> "$REPORT_FILE"

  log_success "Report generated: $REPORT_FILE"
}

################################################################################
# Main Execution
################################################################################

main() {
  echo ""
  echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
  echo "â•‘                                                              â•‘"
  echo "â•‘       PRE-DEPLOY TEST SUITE - SOLUÃ‡ÃƒO B+C                   â•‘"
  echo "â•‘                                                              â•‘"
  echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
  echo ""

  log_info "Starting pre-deploy tests..."
  log_info "Log file: $LOG_FILE"
  echo ""

  # Parse arguments
  CATEGORY=""
  PARALLEL=false
  QUICK=false
  GENERATE_REPORT=false

  while [[ $# -gt 0 ]]; do
    case $1 in
      --category)
        CATEGORY="$2"
        shift 2
        ;;
      --parallel)
        PARALLEL=true
        shift
        ;;
      --quick)
        QUICK=true
        shift
        ;;
      --report)
        GENERATE_REPORT=true
        shift
        ;;
      *)
        echo "Unknown option: $1"
        echo "Usage: $0 [--category CATEGORIA] [--parallel] [--quick] [--report]"
        exit 1
        ;;
    esac
  done

  # Execute tests based on category
  if [ -z "$CATEGORY" ]; then
    # Run all categories
    run_code_tests

    if [ "$QUICK" = false ]; then
      run_feature_tests
      run_ui_tests
      run_performance_tests
    fi

    run_security_tests

    if [ "$QUICK" = false ]; then
      run_regression_tests
    fi
  else
    # Run specific category
    case $CATEGORY in
      1) run_code_tests ;;
      2) run_feature_tests ;;
      3) run_ui_tests ;;
      4) run_performance_tests ;;
      5) run_security_tests ;;
      6) run_regression_tests ;;
      *)
        echo "Invalid category: $CATEGORY (must be 1-6)"
        exit 1
        ;;
    esac
  fi

  # Generate report if requested
  if [ "$GENERATE_REPORT" = true ]; then
    generate_report
  fi

  # Print summary
  echo ""
  section_header "TEST SUMMARY"
  echo "Total Tests:        $TOTAL_TESTS"
  echo "Passed:             $PASSED_TESTS"
  echo "Failed:             $FAILED_TESTS"
  echo "Critical Failures:  $CRITICAL_FAILURES"
  echo ""

  if [ "$CRITICAL_FAILURES" -eq 0 ] && [ "$FAILED_TESTS" -le 6 ]; then
    echo -e "${GREEN}âœ… DEPLOY APPROVED${NC}"
    echo "All critical tests passed. Safe to deploy."
    exit 0
  else
    echo -e "${RED}âŒ DEPLOY BLOCKED${NC}"
    echo "Critical failures detected. Fix issues before deploying."
    exit 1
  fi
}

# Run main function
main "$@"
